{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba Técnica - Data Scientist - NLP Prueba 2\n",
    "\n",
    "## Clasificación de opiniones Positivas y Negativas\n",
    "\n",
    "#### La percepción de los clientes sobre los contenidos que ofrecen las empresas o plataformas, es de gran importancia para la mejora de procesos y contenidos dentro de la misma. Esta percepción, no necesariamente se analiza mediante encuestas con preguntas cerradas, por lo que, se deben utilizar metodologías propias del Procesamiento de Lenguaje Natural (NLP). Este procesamiento, ha cobrado importancia para el desarrollo de IA. \n",
    "\n",
    "#### En este documento, se presenta el análisis de las reseñas escritas por críticos/aficionados de ciertos contenidos, las cuales, están etiquetadas como positivas y negativas. Estas son etiquetas polarizadas, y el objetivo, es identificar cuándo una reseña es positiva o negativa. Esto se puede lograr, mediante el uso del Análisis de Sentimientos, con NLP, utilizando técnicas de Aprendizaje Supervisado, debido a que los datos están etiquetados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Se cargan los paquetes requeridos para el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dada la importancia de la modelación en Ciencia de Datos para un equipo de producción, se requiere especificar el Pipeline del modelo que se va a implementar. De este modo, se describe el Pipeline de este trabajo:\n",
    "\n",
    "#### 1. Partición de las reseñas.\n",
    "#### 2. Preprocesamiento de las reseñas (Tokenización, Normalización, Remoción de palabras \"stop\", Vectorización, Representación tf-idf).\n",
    "#### 3. Modelado de las reseñas\n",
    "#### 4. Entrenamiento y prueba del modelo\n",
    "#### 5. Evaluación del modelo\n",
    "#### 6. Despliegue del modelo\n",
    "#### 7. Monitoreo y mantenimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in exotica everybody is watching , and what is...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>some of the gags are so carefully innocuous th...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>press junkets are a haven for control freaks .</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>then i realized he was , and i was watching it .</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uh huh .</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0  in exotica everybody is watching , and what is...  pos\n",
       "1  some of the gags are so carefully innocuous th...  neg\n",
       "2     press junkets are a haven for control freaks .  neg\n",
       "3   then i realized he was , and i was watching it .  neg\n",
       "4                                           uh huh .  neg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/hec-gallego/nlp-prueba2/main/NLP%20prueba%202.csv')\n",
    "df = df[['text', 'tag']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    25434\n",
       "pos     3968\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en el conjunto de datos, parece que la etiqueta está desbalanceada. Sin embargo, aún se puede trabajar con ella. Lo siguiente, es binarizar dicha etiqueta, para lo cual, se realiza lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25442\n",
       "1     3968\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['tag'] = np.where(df['tag']=='pos', 1, 0)\n",
    "df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Partición de las reseñas\n",
    "\n",
    "La partición de las reseñas, consiste en determinar un conjunto de datos para Entrenamiento (Train), y otro conjunto para la Prueba (Test). En este caso, se hará una partición 70/30, es decir, 70% de los datos para entrenamiento, y el otro 30% para la prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de entrenamiento:((20587,), (20587,))\n",
      "Dimensiones de prueba:((8823,), (8823,))\n",
      "0    17784\n",
      "1     2803\n",
      "Name: tag, dtype: int64\n",
      "0    7658\n",
      "1    1165\n",
      "Name: tag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['tag'], test_size = 0.3, random_state = 1)\n",
    "\n",
    "print(f'Dimensiones de entrenamiento:{X_train.shape, y_train.shape}')\n",
    "print(f'Dimensiones de prueba:{X_test.shape, y_test.shape}')\n",
    "index1 = range(0,20586)\n",
    "index2 = range(0,8822)\n",
    "X_train.reindex(index1)\n",
    "X_test.reindex(index2)\n",
    "y_train.reindex(index1)\n",
    "y_test.reindex(index2)\n",
    "\n",
    "# No está de más, revisar la distribución de la etiqueta\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento de las reseñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and singer sinead o'connor appears rather effe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's time to take cover .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the director's negative view on the catholic c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uh huh .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he's covered in dirt and has a gun to her neck...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0  and singer sinead o'connor appears rather effe...    0\n",
       "1                          it's time to take cover .    0\n",
       "2  the director's negative view on the catholic c...    0\n",
       "3                                           uh huh .    0\n",
       "4  he's covered in dirt and has a gun to her neck...    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([X_train, y_train], axis = 1)\n",
    "test = pd.concat([X_test, y_test], axis = 1)\n",
    "train.reset_index(drop=True, inplace = True)\n",
    "train.reset_index(drop=True, inplace = True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para remover puntuaciones\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_tokenied</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and singer sinead o'connor appears rather effe...</td>\n",
       "      <td>0</td>\n",
       "      <td>and singer sinead oconnor appears rather effec...</td>\n",
       "      <td>and singer sinead oconnor appears rather effec...</td>\n",
       "      <td>[and, singer, sinead, oconnor, appears, rather...</td>\n",
       "      <td>[singer, sinead, oconnor, appears, rather, eff...</td>\n",
       "      <td>[singer, sinead, oconnor, appears, rather, eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's time to take cover .</td>\n",
       "      <td>0</td>\n",
       "      <td>its time to take cover</td>\n",
       "      <td>its time to take cover</td>\n",
       "      <td>[its, time, to, take, cover, ]</td>\n",
       "      <td>[time, take, cover, ]</td>\n",
       "      <td>[time, take, cover, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the director's negative view on the catholic c...</td>\n",
       "      <td>0</td>\n",
       "      <td>the directors negative view on the catholic ch...</td>\n",
       "      <td>the directors negative view on the catholic ch...</td>\n",
       "      <td>[the, directors, negative, view, on, the, cath...</td>\n",
       "      <td>[directors, negative, view, catholic, church, ...</td>\n",
       "      <td>[director, negative, view, catholic, church, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uh huh .</td>\n",
       "      <td>0</td>\n",
       "      <td>uh huh</td>\n",
       "      <td>uh huh</td>\n",
       "      <td>[uh, huh, ]</td>\n",
       "      <td>[uh, huh, ]</td>\n",
       "      <td>[uh, huh, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he's covered in dirt and has a gun to her neck...</td>\n",
       "      <td>1</td>\n",
       "      <td>hes covered in dirt and has a gun to her neck ...</td>\n",
       "      <td>hes covered in dirt and has a gun to her neck ...</td>\n",
       "      <td>[hes, covered, in, dirt, and, has, a, gun, to,...</td>\n",
       "      <td>[hes, covered, dirt, gun, neck, little, crampe...</td>\n",
       "      <td>[he, covered, dirt, gun, neck, little, cramped...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag  \\\n",
       "0  and singer sinead o'connor appears rather effe...    0   \n",
       "1                          it's time to take cover .    0   \n",
       "2  the director's negative view on the catholic c...    0   \n",
       "3                                           uh huh .    0   \n",
       "4  he's covered in dirt and has a gun to her neck...    1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  and singer sinead oconnor appears rather effec...   \n",
       "1                            its time to take cover    \n",
       "2  the directors negative view on the catholic ch...   \n",
       "3                                            uh huh    \n",
       "4  hes covered in dirt and has a gun to her neck ...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  and singer sinead oconnor appears rather effec...   \n",
       "1                            its time to take cover    \n",
       "2  the directors negative view on the catholic ch...   \n",
       "3                                            uh huh    \n",
       "4  hes covered in dirt and has a gun to her neck ...   \n",
       "\n",
       "                                       text_tokenied  \\\n",
       "0  [and, singer, sinead, oconnor, appears, rather...   \n",
       "1                     [its, time, to, take, cover, ]   \n",
       "2  [the, directors, negative, view, on, the, cath...   \n",
       "3                                        [uh, huh, ]   \n",
       "4  [hes, covered, in, dirt, and, has, a, gun, to,...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [singer, sinead, oconnor, appears, rather, eff...   \n",
       "1                              [time, take, cover, ]   \n",
       "2  [directors, negative, view, catholic, church, ...   \n",
       "3                                        [uh, huh, ]   \n",
       "4  [hes, covered, dirt, gun, neck, little, crampe...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  [singer, sinead, oconnor, appears, rather, eff...  \n",
       "1                              [time, take, cover, ]  \n",
       "2  [director, negative, view, catholic, church, i...  \n",
       "3                                        [uh, huh, ]  \n",
       "4  [he, covered, dirt, gun, neck, little, cramped...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1. Tokenización ignorando signos de puntuación\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in str(text) if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "train['clean_text']= train['text'].apply(lambda x:remove_punctuation(x))\n",
    "train['text_lower']= train['clean_text'].apply(lambda x: x.lower())\n",
    "\n",
    "import re\n",
    "def tokenization(text):\n",
    "    tokens = re.split(r'\\s+',str(text))\n",
    "    return tokens\n",
    "\n",
    "train['text_tokenied']= train['text_lower'].apply(lambda x: tokenization(x))\n",
    "\n",
    "# 2.2. Normalización\n",
    "# 2.2.1. Remoción de palabras \"stop\"\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "train['no_stopwords']= train['text_tokenied'].apply(lambda x:remove_stopwords(x))\n",
    "# 2.2.2. Lematización\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "train['text_lemmatized']=train['no_stopwords'].apply(lambda x:lemmatizer(x))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3. Vectorización\n",
    "countvectorizer = CountVectorizer(analyzer = 'word', stop_words = 'english')\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer = 'word', stop_words = 'english')\n",
    "\n",
    "# Convertimos a matriz\n",
    "train_count = countvectorizer.fit_transform(train['text_lower'])\n",
    "train_tfidf = tfidfvectorizer.fit_transform(train['text_lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recuperamos los tokens\n",
    "count_tokens = countvectorizer.get_feature_names()\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "df_tfidfvect = pd.DataFrame.sparse.from_spmatrix(train_tfidf, columns = tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000aweek</th>\n",
       "      <th>000foot</th>\n",
       "      <th>000paltry</th>\n",
       "      <th>007</th>\n",
       "      <th>00s</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zoot</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerabrahamszucker</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwicks</th>\n",
       "      <th>zwigoffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000aweek  000foot  000paltry  007  00s   03   04   05  ...  \\\n",
       "0  0.0  0.0       0.0      0.0        0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1  0.0  0.0       0.0      0.0        0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2  0.0  0.0       0.0      0.0        0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3  0.0  0.0       0.0      0.0        0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4  0.0  0.0       0.0      0.0        0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "   zooms  zoot  zorro  zucker  zuckerabrahamszucker  zuko  zulu  zwick  \\\n",
       "0    0.0   0.0    0.0     0.0                   0.0   0.0   0.0    0.0   \n",
       "1    0.0   0.0    0.0     0.0                   0.0   0.0   0.0    0.0   \n",
       "2    0.0   0.0    0.0     0.0                   0.0   0.0   0.0    0.0   \n",
       "3    0.0   0.0    0.0     0.0                   0.0   0.0   0.0    0.0   \n",
       "4    0.0   0.0    0.0     0.0                   0.0   0.0   0.0    0.0   \n",
       "\n",
       "   zwicks  zwigoffs  \n",
       "0     0.0       0.0  \n",
       "1     0.0       0.0  \n",
       "2     0.0       0.0  \n",
       "3     0.0       0.0  \n",
       "4     0.0       0.0  \n",
       "\n",
       "[5 rows x 27550 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidfvect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['clean_text']= test['text'].apply(lambda x:remove_punctuation(x))\n",
    "test['text_lower']= test['clean_text'].apply(lambda x: x.lower())\n",
    "\n",
    "test_count = countvectorizer.fit_transform(test['text_lower'])\n",
    "test_tfidf = tfidfvectorizer.fit_transform(test['text_lower'])\n",
    "\n",
    "test_count_tokens = countvectorizer.get_feature_names()\n",
    "test_tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "\n",
    "test_tfidfvect = pd.DataFrame.sparse.from_spmatrix(test_tfidf, columns = test_tfidf_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modelado de las reseñas\n",
    "\n",
    "#### Una vez que el texto de las reseñas fue preprocesado, se ajusta un modelo de clasificación. El modelo  que se utilizará, es un clasificador de Bayes Ingenuo Binario. Este modelo funciona bien cuando se tiene una matriz dispersa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8874532471948317"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB(binarize=0.0)\n",
    "bnb.fit(df_tfidfvect, train['tag'])\n",
    "bnb.score(df_tfidfvect, train['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora, se obtienen las predicciones del modelo ajustado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.predict(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El principal objetivo de la modelación para este documento, es identificar cuándo una opinión es positiva o negativa. Para ello, se extraen las características, o palabras, que contribuyen más a la probabilidad de que una opinión sea positiva o negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film' 'movie' 'like' 'just' 'time' 'good' 'bad' 'character' 'story'\n",
      " 'films']\n",
      "['film' 'movie' 'like' 'just' 'films' 'good' 'story' 'life' 'time' 'way']\n"
     ]
    }
   ],
   "source": [
    "neg_class_prob_sorted = bnb.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = bnb.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "print(np.take(tfidfvectorizer.get_feature_names(), neg_class_prob_sorted[:10]))\n",
    "print(np.take(tfidfvectorizer.get_feature_names(), pos_class_prob_sorted[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84458475 0.8436134  0.84357542 0.84697595 0.84406121]\n",
      "Accuracy: 0.84 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "bnb_clf_scores = sklearn.model_selection.cross_val_score(bnb, df_tfidfvect, train['tag'], cv=5)\n",
    "\n",
    "print(bnb_clf_scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\"%(bnb_clf_scores.mean(), bnb_clf_scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17146   638]\n",
      " [ 2562   241]]\n"
     ]
    }
   ],
   "source": [
    "bnb_clf_pred = sklearn.model_selection.cross_val_predict(bnb, df_tfidfvect, train['tag'], cv=5)\n",
    "print(confusion_matrix(train['tag'], bnb_clf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De acuerdo con los resultados obtenidos, se identificó que, aquellas opiniones negativas que tuvieron más importancia, se referían principalmente a películas y a los personajes de las mismas. En el caso de las opiniones positivas, se inclinaban también hacia las películas y las historias calificadas como buenas.\n",
    "#### Respecto al modelo, se encontró una precisión del 84%, de acuerdo con el resultado de la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
